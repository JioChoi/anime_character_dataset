{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0848e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Collecting huggingface-hub>=0.24.0\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.11.16-cp310-cp310-win_amd64.whl (442 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Collecting requests>=2.32.2\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from datasets) (2.2.4)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.20.0-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.4.3-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Installing collected packages: multidict, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.30.2 idna-3.10 multidict-6.4.3 multiprocess-0.70.16 pandas-2.2.3 requests-2.32.3 yarl-1.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jioch\\desktop\\anime_character_dataset\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiochoi/Projects/anime_character_dataset/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 8603394/8603394 [00:10<00:00, 785024.41 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\n",
    "    \"isek-ai/danbooru-tags-2024\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54955fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 8603394/8603394 [02:17<00:00, 62373.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove original characters, and incomplete data\n",
    "data = data.filter(lambda x: x[\"copyright\"] is not None and x[\"character\"] is not None and x[\"general\"] is not None and \"original\" not in x[\"copyright\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7235553 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7235553/7235553 [20:51<00:00, 5781.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create raw_characters.json (takes about 20 minutes)\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "characters = {}\n",
    "\n",
    "for temp in tqdm(data):\n",
    "    data_characters = temp[\"character\"].split(\", \")\n",
    "    data_copyright = temp[\"copyright\"].split(\", \")\n",
    "    data_general = temp[\"general\"].split(\", \")\n",
    "\n",
    "    # process character data\n",
    "    for character in data_characters:\n",
    "        if character not in characters:\n",
    "            characters[character] = {\n",
    "                \"count\": 1,\n",
    "                \"image\": \"\",\n",
    "                \"copyright\": {},\n",
    "                \"tags\": {}\n",
    "            }\n",
    "        else:\n",
    "            characters[character][\"count\"] += 1\n",
    "        \n",
    "        # process copyright data\n",
    "        for copyright in data_copyright:\n",
    "            if copyright not in characters[character][\"copyright\"]:\n",
    "                characters[character][\"copyright\"][copyright] = 1\n",
    "            else:\n",
    "                characters[character][\"copyright\"][copyright] += 1\n",
    "        \n",
    "        # process tags data\n",
    "        if \"solo\" in data_general:\n",
    "            for general in data_general:\n",
    "                if general not in characters[character][\"tags\"]:\n",
    "                    characters[character][\"tags\"][general] = 1\n",
    "                else:\n",
    "                    characters[character][\"tags\"][general] += 1\n",
    "\n",
    "# Save the characters dictionary to a JSON file\n",
    "with open(\"raw_characters.json\", \"w\") as f:\n",
    "    json.dump(characters, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa650275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235726/235726 [00:19<00:00, 12374.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create characters.json (takes about 30 seconds)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "# Filter out copyrights with image count less than {copyright_threshold}% of the total images\n",
    "copyright_threshold = 60\n",
    "\n",
    "# Filter out tags with image count less than {tag_threshold}% of the total images\n",
    "tag_threshold = 15\n",
    "\n",
    "# Filter out characters less than {character_threshold} images\n",
    "character_threshold = 15\n",
    "\n",
    "# Filter out traits with image count less than {trait_threshold} images\n",
    "trait_threshold = 5\n",
    "trait_consideration_threshold = 85\n",
    "\n",
    "eye_colors = [\"aqua eyes\", \"black eyes\", \"blue eyes\", \"brown eyes\", \"green eyes\", \"grey eyes\", \"orange eyes\", \"purple eyes\", \"pink eyes\", \"red eyes\", \"white eyes\", \"yellow eyes\", \"heterochromia\"]\n",
    "hair_colors = [\"aqua hair\", \"black hair\", \"blonde hair\", \"blue hair\", \"brown hair\", \"green hair\", \"grey hair\", \"orange hair\", \"purple hair\", \"pink hair\", \"red hair\", \"white hair\"]\n",
    "hair_length = [\"very short hair\", \"short hair\", \"medium hair\", \"long hair\", \"very long hair\", \"absurdly long hair\", \"big hair\", \"bald\"]\n",
    "skin_colors = [\"dark skin\", \"pale skin\", \"black skin\", \"blue skin\", \"green skin\", \"grey skin\", \"orange skin\", \"pink skin\", \"purple skin\", \"red skin\", \"silver skin\", \"white skin\", \"yellow skin\"]\n",
    "chest_sizes = [\"flat chest\", \"small breasts\", \"medium breasts\", \"large breasts\", \"huge breasts\", \"gigantic breasts\"]\n",
    "genders = [\"1boy\", \"1girl\", \"pokemon (creature)\"]\n",
    "\n",
    "with open(\"raw_characters.json\", \"r\") as f:\n",
    "    characters = json.load(f)\n",
    "\n",
    "for character in tqdm(characters):\n",
    "    count = characters[character][\"count\"]\n",
    "    count_tag_max = max(characters[character][\"tags\"].values()) if len(characters[character][\"tags\"]) > 0 else 0\n",
    "    count_copyright_max = max(characters[character][\"copyright\"].values()) if len(characters[character][\"copyright\"]) > 0 else 0\n",
    "    copyright_count = copyright_threshold * count_copyright_max / 100\n",
    "    tag_count = tag_threshold * count_tag_max / 100\n",
    "    trait_count = trait_threshold * count_tag_max / 100\n",
    "\n",
    "    original_tags = characters[character][\"tags\"].copy()\n",
    "\n",
    "    # Convert copyrights and tags to list\n",
    "    characters[character][\"copyright\"] = {k: v for k, v in characters[character][\"copyright\"].items() if v >= copyright_count}\n",
    "    characters[character][\"tags\"] = {k: v for k, v in original_tags.items() if v >= tag_count}\n",
    "    \n",
    "    # Sort the copyrights and tags by count in ascending order in list format\n",
    "    characters[character][\"copyright\"] = sorted(characters[character][\"copyright\"].items(), key=lambda x: x[1], reverse=True)\n",
    "    characters[character][\"tags\"] = sorted(characters[character][\"tags\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Traits\n",
    "    characters[character][\"traits\"] = {\n",
    "        \"eye_color\": [x for x in original_tags.items() if x[0] in eye_colors and x[1]],\n",
    "        \"hair_color\": [x for x in original_tags.items() if x[0] in hair_colors and x[1]],\n",
    "        \"hair_length\": [x for x in original_tags.items() if x[0] in hair_length and x[1]],\n",
    "        \"skin_color\": [x for x in original_tags.items() if x[0] in skin_colors and x[1] >= trait_count],\n",
    "        \"chest_size\": [x for x in original_tags.items() if x[0] in chest_sizes and x[1]],\n",
    "        \"gender\": [x for x in original_tags.items() if x[0] in genders and x[1]],\n",
    "    }\n",
    "\n",
    "    # Filter out traits with image count less than {trait_consideration_threshold}% of the first trait\n",
    "    for trait in characters[character][\"traits\"]:\n",
    "        if len(characters[character][\"traits\"][trait]) > 0:\n",
    "            characters[character][\"traits\"][trait] = sorted(characters[character][\"traits\"][trait], key=lambda x: x[1], reverse=True)\n",
    "            trait_count = characters[character][\"traits\"][trait][0][1] * trait_consideration_threshold / 100\n",
    "            characters[character][\"traits\"][trait] = [x[0] for x in characters[character][\"traits\"][trait] if x[1] >= trait_count]\n",
    "\n",
    "    if len(characters[character][\"traits\"][\"skin_color\"]) == 0:\n",
    "        characters[character][\"traits\"][\"skin_color\"] = [\"normal skin\"]\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries\n",
    "characters_list = []\n",
    "for character, data in characters.items():\n",
    "    if data[\"count\"] < character_threshold:\n",
    "        continue\n",
    "\n",
    "    characters_list.append({\n",
    "        \"name\": character,\n",
    "        \"hash\": hashlib.md5(character.encode()).hexdigest(),\n",
    "        \"count\": data[\"count\"],\n",
    "        \"copyright\": data[\"copyright\"],\n",
    "        \"tags\": data[\"tags\"],\n",
    "        \"traits\": data[\"traits\"]\n",
    "    })\n",
    "\n",
    "# Sort the list of characters by count in ascending order\n",
    "characters_list = sorted(characters_list, key=lambda x: x[\"count\"], reverse=True)\n",
    "\n",
    "characters_min_list = []\n",
    "for character in characters_list:\n",
    "    if character[\"copyright\"] == []:\n",
    "        continue\n",
    "    if character[\"tags\"] == []:\n",
    "        continue\n",
    "\n",
    "    del character[\"tags\"]\n",
    "    del character[\"count\"]\n",
    "    del character[\"copyright\"]\n",
    "\n",
    "    characters_min_list.append(character)\n",
    "\n",
    "# Save the characters list to a JSON file\n",
    "with open(\"characters.json\", \"w\") as f:\n",
    "    json.dump(characters_list, f, indent=4)\n",
    "with open(\"characters_min.json\", \"w\") as f:\n",
    "    json.dump(characters_min_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539c8a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52597"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters in characters.json?\n",
    "len(characters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdae2058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'akemi homura',\n",
       "  'hash': 'd9e26b9fefc649108e624c33128a5cbb',\n",
       "  'traits': {'eye_color': ['purple eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'akemi homura (magical girl)',\n",
       "  'hash': '20e0cc6ab47313c307e60981e400e307',\n",
       "  'traits': {'eye_color': ['purple eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts', 'medium breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'akatsuki (kancolle)',\n",
       "  'hash': '433c1eef7e620aa2cc399cbde1063101',\n",
       "  'traits': {'eye_color': ['purple eyes'],\n",
       "   'hair_color': ['purple hair', 'black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'yazawa nico',\n",
       "  'hash': '8df6b1d88945f67a17cb5d4e45015014',\n",
       "  'traits': {'eye_color': ['red eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'aris (blue archive)',\n",
       "  'hash': 'b064b01cf937828e5092b147ba57f5ad',\n",
       "  'traits': {'eye_color': ['blue eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'marnie (pokemon)',\n",
       "  'hash': 'f0cb72c400633699f1b34ad09b889f47',\n",
       "  'traits': {'eye_color': ['green eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['medium hair', 'long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'kisaki (blue archive)',\n",
       "  'hash': '0ffe05df104a040ee50098ad471532a3',\n",
       "  'traits': {'eye_color': ['grey eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'kitakami (kancolle)',\n",
       "  'hash': '5565082fc8f87c362305a1ea921c8deb',\n",
       "  'traits': {'eye_color': ['purple eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'ooyodo (kancolle)',\n",
       "  'hash': '57a4311f4e10403bff76ed1f2d855685',\n",
       "  'traits': {'eye_color': ['green eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}},\n",
       " {'name': 'asashio (kancolle)',\n",
       "  'hash': 'b89af1194af539c5170be9e6f7531192',\n",
       "  'traits': {'eye_color': ['blue eyes'],\n",
       "   'hair_color': ['black hair'],\n",
       "   'hair_length': ['long hair'],\n",
       "   'skin_color': ['normal skin'],\n",
       "   'chest_size': ['small breasts'],\n",
       "   'gender': ['1girl']}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search test\n",
    "import json\n",
    "\n",
    "with open(\"characters_min.json\", \"r\") as f:\n",
    "    characters = json.load(f)\n",
    "\n",
    "def check_trait(character, traits):\n",
    "    for trait, values in traits.items():\n",
    "        for value in values:\n",
    "            if value not in character[\"traits\"][trait]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def search_character(traits):\n",
    "    results = []\n",
    "    for character in characters:\n",
    "        if check_trait(character, traits):\n",
    "            results.append(character)\n",
    "    return results[:10]\n",
    "\n",
    "search_character({\n",
    "    \"eye_color\": [],\n",
    "    \"hair_color\": [\"black hair\"],\n",
    "    \"hair_length\": [\"long hair\"],\n",
    "    \"skin_color\": [],\n",
    "    \"chest_size\": [\"small breasts\"],\n",
    "    \"gender\": [\"1girl\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3fec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52597/52597 [00:00<00:00, 424216.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create copyrights.json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "with open(\"characters.json\", \"r\") as f:\n",
    "    characters = json.load(f)\n",
    "\n",
    "copyrights = {}\n",
    "\n",
    "for index in tqdm(range(len(characters))):\n",
    "    for copyright in characters[index][\"copyright\"]:\n",
    "        if copyright[0] not in copyrights:\n",
    "            copyrights[copyright[0]] = {\n",
    "                \"count\": 0,\n",
    "                \"popularity\": 0,\n",
    "                \"hash\": hashlib.md5(copyright[0].encode()).hexdigest(),\n",
    "                \"characters\": []\n",
    "            }\n",
    "        \n",
    "        copyrights[copyright[0]][\"count\"] += 1\n",
    "        copyrights[copyright[0]][\"characters\"].append(characters[index][\"hash\"])\n",
    "        copyrights[copyright[0]][\"popularity\"] = max(copyrights[copyright[0]][\"popularity\"], characters[index][\"count\"])\n",
    "    \n",
    "# Sort the copyrights by popularity in ascending order in list format\n",
    "copyrights = sorted(copyrights.items(), key=lambda x: x[1][\"popularity\"], reverse=True)\n",
    "\n",
    "with open(\"copyrights.json\", \"w\") as f:\n",
    "    json.dump(copyrights, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
