{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0848e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.13/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from datasets) (2.2.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.13/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiochoi/Projects/anime_character_dataset/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 8603394/8603394 [00:10<00:00, 785024.41 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\n",
    "    \"isek-ai/danbooru-tags-2024\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54955fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 8603394/8603394 [02:17<00:00, 62373.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove original characters, and incomplete data\n",
    "data = data.filter(lambda x: x[\"copyright\"] is not None and x[\"character\"] is not None and x[\"general\"] is not None and \"original\" not in x[\"copyright\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151c2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7235553 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7235553/7235553 [20:51<00:00, 5781.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create raw_characters.json (takes about 20 minutes)\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "characters = {}\n",
    "\n",
    "for temp in tqdm(data):\n",
    "    data_characters = temp[\"character\"].split(\", \")\n",
    "    data_copyright = temp[\"copyright\"].split(\", \")\n",
    "    data_general = temp[\"general\"].split(\", \")\n",
    "\n",
    "    # process character data\n",
    "    for character in data_characters:\n",
    "        if character not in characters:\n",
    "            characters[character] = {\n",
    "                \"count\": 1,\n",
    "                \"image\": \"\",\n",
    "                \"copyright\": {},\n",
    "                \"tags\": {}\n",
    "            }\n",
    "        else:\n",
    "            characters[character][\"count\"] += 1\n",
    "        \n",
    "        # process copyright data\n",
    "        for copyright in data_copyright:\n",
    "            if copyright not in characters[character][\"copyright\"]:\n",
    "                characters[character][\"copyright\"][copyright] = 1\n",
    "            else:\n",
    "                characters[character][\"copyright\"][copyright] += 1\n",
    "        \n",
    "        # process tags data\n",
    "        if \"solo\" in data_general:\n",
    "            for general in data_general:\n",
    "                if general not in characters[character][\"tags\"]:\n",
    "                    characters[character][\"tags\"][general] = 1\n",
    "                else:\n",
    "                    characters[character][\"tags\"][general] += 1\n",
    "\n",
    "# Save the characters dictionary to a JSON file\n",
    "with open(\"raw_characters.json\", \"w\") as f:\n",
    "    json.dump(characters, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa650275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235726/235726 [00:03<00:00, 59108.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create characters.json (takes about 30 seconds)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Filter out copyrights with image count less than {copyright_threshold}% of the total images\n",
    "copyright_threshold = 60\n",
    "\n",
    "# Filter out tags with image count less than {tag_threshold}% of the total images\n",
    "tag_threshold = 10\n",
    "\n",
    "# Filter out characters less than {character_threshold} images\n",
    "character_threshold = 15\n",
    "\n",
    "with open(\"raw_characters.json\", \"r\") as f:\n",
    "    characters = json.load(f) \n",
    "\n",
    "for character in tqdm(characters):\n",
    "    count = characters[character][\"count\"]\n",
    "    copyright_count = copyright_threshold * count / 100\n",
    "    tag_count = tag_threshold * count / 100\n",
    "\n",
    "    # Convert copyrights and tags to list\n",
    "    characters[character][\"copyright\"] = {k: v for k, v in characters[character][\"copyright\"].items() if v >= copyright_count}\n",
    "    characters[character][\"tags\"] = {k: v for k, v in characters[character][\"tags\"].items() if v >= tag_count}\n",
    "    \n",
    "    # Sort the copyrights and tags by count in ascending order in list format\n",
    "    characters[character][\"copyright\"] = sorted(characters[character][\"copyright\"].items(), key=lambda x: x[1], reverse=True)\n",
    "    characters[character][\"tags\"] = sorted(characters[character][\"tags\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries\n",
    "characters_list = []\n",
    "for character, data in characters.items():\n",
    "    if data[\"count\"] < character_threshold:\n",
    "        continue\n",
    "\n",
    "    characters_list.append({\n",
    "        \"name\": character,\n",
    "        \"count\": data[\"count\"],\n",
    "        \"copyright\": data[\"copyright\"],\n",
    "        \"tags\": data[\"tags\"]\n",
    "    })\n",
    "\n",
    "# Save the characters list to a JSON file\n",
    "with open(\"characters.json\", \"w\") as f:\n",
    "    json.dump(characters_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539c8a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52597"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters in characters.json?\n",
    "len(characters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f3fec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52597/52597 [00:00<00:00, 706483.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create copyrights.json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "with open(\"characters.json\", \"r\") as f:\n",
    "    characters = json.load(f)\n",
    "\n",
    "copyrights = {}\n",
    "\n",
    "for index in tqdm(range(len(characters))):\n",
    "    for copyright in characters[index][\"copyright\"]:\n",
    "        if copyright[0] not in copyrights:\n",
    "            copyrights[copyright[0]] = {\n",
    "                \"count\": 0,\n",
    "                \"popularity\": 0,\n",
    "                \"characters\": []\n",
    "            }\n",
    "        \n",
    "        copyrights[copyright[0]][\"count\"] += 1\n",
    "        copyrights[copyright[0]][\"characters\"].append(index)\n",
    "        copyrights[copyright[0]][\"popularity\"] = max(copyrights[copyright[0]][\"popularity\"], characters[index][\"count\"])\n",
    "    \n",
    "# Sort the copyrights by popularity in ascending order in list format\n",
    "copyrights = sorted(copyrights.items(), key=lambda x: x[1][\"popularity\"], reverse=True)\n",
    "\n",
    "with open(\"copyrights.json\", \"w\") as f:\n",
    "    json.dump(copyrights, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
